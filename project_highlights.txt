• Integrated LangChain (~0.2.0) and FAISS vectorstore with OpenAI/Mistral-7B models, enabling intelligent RAG over 25+ research papers with 85%+ answer relevance
• Built section-aware document processing with 1000-character chunks and 100-character overlap for optimal context preservation, reducing hallucinations by ~40%
• Indexed arXiv papers with automated metadata extraction, supporting 10+ academic categories (cs.AI, cs.CL, etc.) with automatic citation network generation
• Developed hybrid LLM support with cloud/local model fallbacks (latency: ~2.2s for queries over 5+ documents)
• Created multi-paper comparison system analyzing methodologies, results, and strengths across papers with 95% source traceability
